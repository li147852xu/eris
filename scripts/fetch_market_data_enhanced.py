"""å¢å¼ºç‰ˆå¸‚åœºæ•°æ®çˆ¬å– - æ•´åˆå¤šä¸ªæ•°æ®æº"""
import akshare as ak
import pandas as pd
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List
from loguru import logger
from tqdm import tqdm
import sys
import time

sys.path.append(str(Path(__file__).parent.parent))
from config import RAW_DATA_DIR, PROCESSED_DATA_DIR, LOG_DIR

# é…ç½®æ—¥å¿—
logger.add(LOG_DIR / "fetch_market.log", rotation="10 MB")


class EnhancedMarketDataFetcher:
    """å¢å¼ºç‰ˆå¸‚åœºæ•°æ®è·å–å™¨"""
    
    def __init__(self):
        self.raw_data_dir = RAW_DATA_DIR
        
    def fetch_all_data_for_dates(self, dates: List[str]):
        """æ‰¹é‡è·å–å¤šä¸ªæ—¥æœŸçš„æ•°æ®"""
        logger.info(f"å¼€å§‹æ‰¹é‡è·å– {len(dates)} ä¸ªæ—¥æœŸçš„å¸‚åœºæ•°æ®")
        
        results = {}
        
        with tqdm(dates, desc="ğŸ“ˆ çˆ¬å–å¸‚åœºæ•°æ®", unit="å¤©", colour="cyan") as pbar:
            for date in pbar:
                pbar.set_description(f"ğŸ“ˆ çˆ¬å– {date}")
                try:
                    data = self.fetch_date_data(date)
                    results[date] = data
                    self.save_market_data(date, data)
                    pbar.set_postfix({"æˆåŠŸ": len(results)})
                    time.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«
                except Exception as e:
                    logger.error(f"è·å– {date} å¤±è´¥: {e}")
                    pbar.set_postfix({"æˆåŠŸ": len(results), "å¤±è´¥": len(dates)-len(results)})
        
        logger.info(f"âœ… æˆåŠŸè·å– {len(results)}/{len(dates)} ä¸ªæ—¥æœŸçš„æ•°æ®")
        return results
    
    def fetch_date_data(self, date: str) -> Dict:
        """è·å–å•æ—¥æ‰€æœ‰å¸‚åœºæ•°æ®"""
        data = {
            'date': date,
            'indices': self.fetch_indices(date),
            'market_stats': self.fetch_market_stats(date),
            'fund_flow': self.fetch_fund_flow(date),
            'top_sectors': self.fetch_top_sectors(date),
            'timestamp': datetime.now().isoformat()
        }
        return data
    
    def fetch_indices(self, date: str) -> Dict:
        """è·å–ä¸‰å¤§æŒ‡æ•°æ•°æ®"""
        indices = {}
        
        try:
            # ä¸Šè¯æŒ‡æ•°
            df = ak.stock_zh_index_daily(symbol="sh000001")
            row = df[df['date'] == date]
            if not row.empty:
                indices['ä¸Šè¯æŒ‡æ•°'] = {
                    'code': '000001',
                    'open': float(row.iloc[0]['open']),
                    'close': float(row.iloc[0]['close']),
                    'high': float(row.iloc[0]['high']),
                    'low': float(row.iloc[0]['low']),
                    'volume': float(row.iloc[0]['volume']),
                    'change': round(row.iloc[0]['close'] - row.iloc[0]['open'], 2),
                    'change_pct': round((row.iloc[0]['close'] - row.iloc[0]['open']) / row.iloc[0]['open'] * 100, 2)
                }
        except Exception as e:
            logger.debug(f"è·å–ä¸Šè¯æŒ‡æ•°å¤±è´¥: {e}")
        
        try:
            # æ·±è¯æˆæŒ‡
            df = ak.stock_zh_index_daily(symbol="sz399001")
            row = df[df['date'] == date]
            if not row.empty:
                indices['æ·±è¯æˆæŒ‡'] = {
                    'code': '399001',
                    'open': float(row.iloc[0]['open']),
                    'close': float(row.iloc[0]['close']),
                    'high': float(row.iloc[0]['high']),
                    'low': float(row.iloc[0]['low']),
                    'volume': float(row.iloc[0]['volume']),
                    'change': round(row.iloc[0]['close'] - row.iloc[0]['open'], 2),
                    'change_pct': round((row.iloc[0]['close'] - row.iloc[0]['open']) / row.iloc[0]['open'] * 100, 2)
                }
        except Exception as e:
            logger.debug(f"è·å–æ·±è¯æˆæŒ‡å¤±è´¥: {e}")
        
        try:
            # åˆ›ä¸šæ¿æŒ‡
            df = ak.stock_zh_index_daily(symbol="sz399006")
            row = df[df['date'] == date]
            if not row.empty:
                indices['åˆ›ä¸šæ¿æŒ‡'] = {
                    'code': '399006',
                    'open': float(row.iloc[0]['open']),
                    'close': float(row.iloc[0]['close']),
                    'high': float(row.iloc[0]['high']),
                    'low': float(row.iloc[0]['low']),
                    'volume': float(row.iloc[0]['volume']),
                    'change': round(row.iloc[0]['close'] - row.iloc[0]['open'], 2),
                    'change_pct': round((row.iloc[0]['close'] - row.iloc[0]['open']) / row.iloc[0]['open'] * 100, 2)
                }
        except Exception as e:
            logger.debug(f"è·å–åˆ›ä¸šæ¿æŒ‡å¤±è´¥: {e}")
        
        return indices
    
    def fetch_market_stats(self, date: str) -> Dict:
        """è·å–å¸‚åœºæ¶¨è·Œç»Ÿè®¡"""
        stats = {}
        
        try:
            # è·å–Aè‚¡å®æ—¶æ•°æ®ï¼ˆæ³¨æ„ï¼šåªèƒ½è·å–å½“æ—¥æˆ–æœ€è¿‘çš„æ•°æ®ï¼‰
            # å¯¹äºå†å²æ•°æ®ï¼Œè¿™ä¸ªæ–¹æ³•å¯èƒ½ä¸å‡†ç¡®
            df = ak.stock_zh_a_spot_em()
            if not df.empty:
                stats = {
                    'up_count': int(len(df[df['æ¶¨è·Œå¹…'] > 0])),
                    'down_count': int(len(df[df['æ¶¨è·Œå¹…'] < 0])),
                    'limit_up': int(len(df[df['æ¶¨è·Œå¹…'] >= 9.9])),
                    'limit_down': int(len(df[df['æ¶¨è·Œå¹…'] <= -9.9])),
                    'total': int(len(df)),
                    'note': 'å½“æ—¥æ•°æ®æˆ–æœ€è¿‘äº¤æ˜“æ—¥æ•°æ®'
                }
        except Exception as e:
            logger.debug(f"è·å–å¸‚åœºç»Ÿè®¡å¤±è´¥: {e}")
        
        return stats
    
    def fetch_fund_flow(self, date: str) -> Dict:
        """è·å–èµ„é‡‘æµå‘"""
        fund_flow = {}
        
        try:
            # åŒ—å‘èµ„é‡‘
            df = ak.stock_hsgt_north_net_flow_in_em(symbol="åŒ—ä¸Šèµ„é‡‘")
            row = df[df['æ—¥æœŸ'] == date]
            if not row.empty:
                fund_flow['åŒ—å‘èµ„é‡‘'] = {
                    'net_inflow': float(row.iloc[0]['å½“æ—¥èµ„é‡‘æµå…¥']),
                    'unit': 'äº¿å…ƒ'
                }
        except Exception as e:
            logger.debug(f"è·å–åŒ—å‘èµ„é‡‘å¤±è´¥: {e}")
        
        return fund_flow
    
    def fetch_top_sectors(self, date: str) -> List[Dict]:
        """è·å–æ¶¨è·Œå¹…å‰10çš„æ¿å—"""
        sectors = []
        
        try:
            # è·å–æ¿å—è¡Œæƒ…
            df = ak.stock_board_industry_name_em()
            if not df.empty and len(df) > 0:
                # æŒ‰æ¶¨è·Œå¹…æ’åºï¼Œå–å‰10
                df_sorted = df.sort_values('æ¶¨è·Œå¹…', ascending=False).head(10)
                for _, row in df_sorted.iterrows():
                    sectors.append({
                        'name': str(row['æ¿å—åç§°']),
                        'change_pct': float(row['æ¶¨è·Œå¹…']),
                        'lead_stock': str(row.get('é¢†æ¶¨è‚¡ç¥¨', 'N/A'))
                    })
        except Exception as e:
            logger.debug(f"è·å–æ¿å—æ•°æ®å¤±è´¥: {e}")
        
        return sectors
    
    def save_market_data(self, date: str, data: Dict):
        """ä¿å­˜å¸‚åœºæ•°æ®"""
        filepath = self.raw_data_dir / f"market_data_{date}.json"
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)


def main():
    """ä¸»å‡½æ•°"""
    # ä»parsed_corpus.jsonè¯»å–æ‰€æœ‰æ—¥æœŸ
    corpus_file = PROCESSED_DATA_DIR / "parsed_corpus.json"
    
    if not corpus_file.exists():
        logger.error("è¯·å…ˆè¿è¡Œ parse_corpus.py è§£æè¯­æ–™")
        return
    
    with open(corpus_file, 'r', encoding='utf-8') as f:
        corpus_data = json.load(f)
    
    dates = [item['date'] for item in corpus_data]
    logger.info(f"å‡†å¤‡çˆ¬å– {len(dates)} ä¸ªæ—¥æœŸçš„æ•°æ®")
    
    fetcher = EnhancedMarketDataFetcher()
    fetcher.fetch_all_data_for_dates(dates)


if __name__ == "__main__":
    main()

