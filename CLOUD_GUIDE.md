# â˜ï¸ äº‘GPUå¹³å°å®Œæ•´ä½¿ç”¨æŒ‡å—

## ðŸŽ¯ æŽ¨èæ–¹æ¡ˆï¼šAutoDL

æˆæœ¬ï¼šÂ¥2-3å…ƒï¼Œè€—æ—¶ï¼šçº¦50åˆ†é’Ÿï¼ˆæ•°æ®ç”Ÿæˆ20åˆ†é’Ÿ + è®­ç»ƒ30åˆ†é’Ÿï¼‰

## ðŸ“‹ å®Œæ•´æµç¨‹

### 1. æ³¨å†ŒAutoDL

è®¿é—®ï¼šhttps://www.autodl.com/

### 2. åˆ›å»ºå®žä¾‹

**æŽ¨èé…ç½®**:
- GPU: RTX 4090 (24GB) æˆ– A100
- é•œåƒ: PyTorch 2.1.0 - Python 3.10 - CUDA 12.1
- ç¡¬ç›˜: 50GB
- è´¹ç”¨: Â¥1.5-2.0/å°æ—¶

### 3. è¿žæŽ¥å®žä¾‹

```bash
# ç‚¹å‡»"JupyterLab"æˆ–ä½¿ç”¨SSHè¿žæŽ¥
# SSHç¤ºä¾‹ï¼š
ssh -p xxxxx root@region-x.autodl.com
```

### 4. å…‹éš†é¡¹ç›®

```bash
cd /root/autodl-tmp
git clone https://github.com/li147852xu/eris.git
cd eris
```

### 5. é…ç½®API Key

```bash
# æ–¹æ³•A: è®¾ç½®çŽ¯å¢ƒå˜é‡ï¼ˆæŽ¨èï¼‰
export OPENAI_API_KEY="sk-2696d151d5a746aca92217ef7fbb513c"
export OPENAI_BASE_URL="https://api.deepseek.com/v1"

# æ–¹æ³•B: åˆ›å»º.envæ–‡ä»¶
cat > .env << EOF
OPENAI_API_KEY=sk-2696d151d5a746aca92217ef7fbb513c
OPENAI_BASE_URL=https://api.deepseek.com/v1
EOF
```

### 6. ä¸€é”®è¿è¡Œ

```bash
# ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼ˆçº¦20åˆ†é’Ÿï¼‰
./run_all.sh

# è®­ç»ƒæ¨¡åž‹ï¼ˆçº¦30-60åˆ†é’Ÿï¼‰
./run_training.sh
```

### 7. æŸ¥çœ‹ç»“æžœ

```bash
# æ£€æŸ¥ç”Ÿæˆçš„è®­ç»ƒæ•°æ®
python3 scripts/check_progress.py

# æµ‹è¯•æ¨¡åž‹
python3 scripts/test_model.py
```

### 8. ä¸‹è½½æ¨¡åž‹

```bash
# æ‰“åŒ…æ¨¡åž‹
cd models
tar -czf financial_assistant.tar.gz financial_assistant/

# ä½¿ç”¨AutoDLæ–‡ä»¶ç®¡ç†å™¨ä¸‹è½½
# æˆ–ä½¿ç”¨scpï¼š
scp -P xxxxx root@region-x.autodl.com:/root/autodl-tmp/eris/models/financial_assistant.tar.gz ./
```

## â±ï¸ è¯¦ç»†æ—¶é—´é¢„ä¼°

### æ•°æ®ç”Ÿæˆé˜¶æ®µ (run_all.sh)

```
çŽ¯å¢ƒæ£€æŸ¥          : 10ç§’
å®‰è£…ä¾èµ–          : 2-3åˆ†é’Ÿ
æ¸…æ´—æ•°æ®          : 10ç§’
è§£æžè¯­æ–™(29å¤©)    : 5ç§’
DeepSeekç”Ÿæˆ      : 15-20åˆ†é’Ÿ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
æ€»è®¡              : ~20åˆ†é’Ÿ
ç”Ÿæˆæ ·æœ¬          : 400-500ä¸ª
```

### æ¨¡åž‹è®­ç»ƒé˜¶æ®µ (run_training.sh)

| GPU | Batch Size | è®­ç»ƒæ—¶é—´ | æ˜¾å­˜å ç”¨ |
|-----|-----------|---------|---------|
| RTX 4090 | 4 | 30-50åˆ†é’Ÿ | ~18GB |
| A100 40GB | 4 | 15-30åˆ†é’Ÿ | ~20GB |
| A100 80GB | 8 | 10-20åˆ†é’Ÿ | ~35GB |
| V100 32GB | 4 | 1-1.5å°æ—¶ | ~20GB |
| T4 16GB | 2 | 2-3å°æ—¶ | ~14GB |

**epochæ•°**: 3è½®
**æ ·æœ¬æ•°**: 400-500ä¸ª

## ðŸ’° æˆæœ¬ä¼°ç®—

### AutoDLæˆæœ¬

| GPUåž‹å· | å•ä»·/å°æ—¶ | é¢„è®¡æ—¶é•¿ | æ€»æˆæœ¬ |
|---------|----------|---------|--------|
| RTX 4090 | Â¥1.5 | 1å°æ—¶ | **Â¥1.5** |
| A100 40GB | Â¥3.0 | 0.8å°æ—¶ | **Â¥2.4** |
| V100 32GB | Â¥1.2 | 1.5å°æ—¶ | **Â¥1.8** |

### DeepSeek APIæˆæœ¬

- 29å¤©æ•°æ®: Â¥0.5-1å…ƒ

### æ€»æˆæœ¬

**å®Œæ•´æµç¨‹**: Â¥2-4å…ƒ

## ðŸ› å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•æŸ¥çœ‹å®žæ—¶è¿›åº¦ï¼Ÿ

```bash
# æŸ¥çœ‹è®­ç»ƒæ•°æ®ç”Ÿæˆè¿›åº¦
python3 scripts/check_progress.py

# æŸ¥çœ‹è®­ç»ƒè¿›åº¦ï¼ˆåœ¨å¦ä¸€ä¸ªç»ˆç«¯ï¼‰
tail -f logs/train_model.log
```

### Q2: è®­ç»ƒä¸­æ–­æ€Žä¹ˆåŠžï¼Ÿ

è®­ç»ƒä¼šè‡ªåŠ¨ä¿å­˜checkpointï¼Œå¯ä»¥ç»§ç»­è®­ç»ƒï¼š
```bash
# æ¨¡åž‹ä¼šä»Žæœ€åŽçš„checkpointç»§ç»­
python3 scripts/train_model.py
```

### Q3: æ˜¾å­˜ä¸è¶³æ€Žä¹ˆåŠžï¼Ÿ

ç¼–è¾‘ `config.py`:
```python
FINETUNE_CONFIG = {
    "batch_size": 2,  # ä»Ž4é™åˆ°2
    "gradient_accumulation_steps": 16,  # ä»Ž8å¢žåˆ°16
}
```

### Q4: å¦‚ä½•æ›´æ¢GPUï¼Ÿ

AutoDLæ”¯æŒçƒ­è¿ç§»ï¼š
1. åˆ›å»ºå¿«ç…§
2. æ–°å»ºæ›´å¼ºGPUçš„å®žä¾‹
3. ä»Žå¿«ç…§æ¢å¤
4. ç»§ç»­è®­ç»ƒ

## ðŸ“Š ç›‘æŽ§è®­ç»ƒ

### æŸ¥çœ‹GPUä½¿ç”¨

```bash
# å®žæ—¶ç›‘æŽ§
watch -n 1 nvidia-smi

# æˆ–ä½¿ç”¨
gpustat -i 1
```

### æŸ¥çœ‹è®­ç»ƒæ—¥å¿—

```bash
# å®žæ—¶æŸ¥çœ‹
tail -f logs/train_model.log

# æŸ¥çœ‹æœ€æ–°
tail -100 logs/train_model.log
```

## ðŸŽ“ ä¼˜åŒ–å»ºè®®

### æå‡è®­ç»ƒé€Ÿåº¦

1. ä½¿ç”¨æ›´å¤§batch_sizeï¼ˆå¦‚æžœæ˜¾å­˜å¤Ÿï¼‰
2. ä½¿ç”¨flash attentionï¼ˆéœ€è¦å®‰è£…flash-attnï¼‰
3. ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆå·²é»˜è®¤å¼€å¯ï¼‰

### æå‡æ¨¡åž‹è´¨é‡

1. å¢žåŠ epochæ•°ï¼ˆ3 â†’ 5ï¼‰
2. ä½¿ç”¨æ›´å¤§çš„LoRA rankï¼ˆ64 â†’ 128ï¼‰
3. ç§¯ç´¯æ›´å¤šè¯­æ–™ï¼ˆ29å¤© â†’ 180å¤©ï¼‰

## ðŸ”„ è¿­ä»£æµç¨‹

### æœ¬åœ°æ·»åŠ æ–°è¯­æ–™

```bash
# 1. æœ¬åœ°æ·»åŠ æ–°çš„.mdæ–‡ä»¶åˆ°data/
# 2. æŽ¨é€åˆ°GitHub
git add data/
git commit -m "æ·»åŠ æ–°è¯­æ–™ï¼š2025-12-03è‡³2025-12-10"
git push
```

### äº‘ç«¯æ›´æ–°è®­ç»ƒ

```bash
# 1. æ‹‰å–æœ€æ–°ä»£ç 
cd /root/autodl-tmp/eris
git pull

# 2. é‡æ–°ç”Ÿæˆè®­ç»ƒæ•°æ®
./run_all.sh

# 3. é‡æ–°è®­ç»ƒ
./run_training.sh
```

## ðŸ’¡ é«˜çº§ç”¨æ³•

### è‡ªå®šä¹‰è®­ç»ƒå‚æ•°

```bash
# ç¼–è¾‘config.pyåŽè®­ç»ƒ
python3 scripts/train_model.py
```

### ä½¿ç”¨æ›´å¤§æ¨¡åž‹

ç¼–è¾‘ `config.py`:
```python
FINETUNE_CONFIG = {
    "base_model": "Qwen/Qwen2.5-14B-Instruct",  # 14Bæ¨¡åž‹
    # éœ€è¦æ›´å¤šæ˜¾å­˜ï¼ˆ32GB+ï¼‰
}
```

### å¤šGPUè®­ç»ƒ

```bash
# ä½¿ç”¨accelerate
accelerate launch scripts/train_model.py
```

## ðŸ“¦ å¯¼å‡ºå’Œéƒ¨ç½²

### å¯¼å‡ºæ¨¡åž‹

```bash
# åˆå¹¶LoRAæƒé‡
python3 -c "
from transformers import AutoModelForCausalLM
from peft import PeftModel

base_model = AutoModelForCausalLM.from_pretrained('Qwen/Qwen2.5-7B-Instruct')
model = PeftModel.from_pretrained(base_model, 'models/financial_assistant')
merged_model = model.merge_and_unload()
merged_model.save_pretrained('models/financial_assistant_merged')
"
```

### éƒ¨ç½²æŽ¨ç†

```bash
# ä½¿ç”¨vLLMåŠ é€ŸæŽ¨ç†
pip install vllm
vllm serve models/financial_assistant_merged --port 8000
```

## ðŸŽ‰ å®Œæˆæ ‡å¿—

è®­ç»ƒå®ŒæˆåŽï¼Œä½ ä¼šçœ‹åˆ°ï¼š

```
=========================================
   âœ… è®­ç»ƒå®Œæˆï¼
=========================================

ðŸ“ æ¨¡åž‹ä¿å­˜åœ¨: models/financial_assistant/

åŒ…å«æ–‡ä»¶:
  - adapter_config.json
  - adapter_model.safetensors
  - tokenizeré…ç½®
  - è®­ç»ƒæ—¥å¿—
```

## ðŸš€ å¿«é€Ÿå‘½ä»¤å‚è€ƒ

```bash
# å®Œæ•´æµç¨‹
git clone https://github.com/li147852xu/eris.git && cd eris
export OPENAI_API_KEY="your_key"
./run_all.sh && ./run_training.sh

# æŸ¥çœ‹è¿›åº¦
python3 scripts/check_progress.py

# æµ‹è¯•æ¨¡åž‹
python3 scripts/test_model.py

# æ›´æ–°æ•°æ®
git pull && ./run_all.sh && ./run_training.sh
```

---

**ç¥è®­ç»ƒé¡ºåˆ©ï¼** ðŸŽ‰

